{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-1: Create tf dataset from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22, -108, 31, -1, 32, 34, 31, 12, 26, 18]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34,31,12,26,18,] # -108 is an error because daily sales number can not be negative \n",
    "daily_sales_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorDataset element_spec=TensorSpec(shape=(11,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=tf.data.Dataset.from_tensors(daily_sales_numbers) # Or\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers) # create a simple tf dataset from a python list\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(26, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales)# individual elements here is in a tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n",
      "12\n",
      "26\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:   # or\n",
    "    print(sales.numpy())   # here converting  this tensor into a numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n",
      "12\n",
      "26\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Iterate through first n elements in tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3): # return only specific element\n",
    "    print(sales.numpy())             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Filter sales numbers that are < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset=tf_dataset.filter(lambda x: x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n",
      "12\n",
      "26\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator(): # fitering negative data\n",
    "    print(sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Convert sales numbers from USA dollars ($) to Bangladeshi Taka (BDT) Assuming 1->80 conversation rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*80) # converting doller to taka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n",
      "1760\n",
      "2480\n",
      "2560\n",
      "2720\n",
      "2480\n",
      "960\n",
      "2080\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator(): \n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n",
      "1760\n",
      "2480\n",
      "2560\n",
      "2720\n",
      "2480\n",
      "960\n",
      "2080\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "tf_datasett=tf_dataset.shuffle(3) # shuffling elements\n",
    "for sales in tf_dataset.as_numpy_iterator(): \n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1584 2232]\n",
      " [1512 2448]\n",
      " [2232  864]\n",
      " [2304 1872]]\n",
      "[[1296]]\n"
     ]
    }
   ],
   "source": [
    "for sales_batch in tf_dataset.batch(4): # creating batch according to specific batch of size\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2: use of tensorflow input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Perform all of the above operations in one shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers) \n",
    "tf_dataset=tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(2).batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 2232]\n",
      "[2304 2448]\n",
      "[2232 1584]\n",
      "[1872 1296]\n",
      "[864]\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator(): \n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Read images using tensorflow input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read images\n",
    "images_dataset=tf.data.Dataset.list_files(r'images/*/*', shuffle=False)\n",
    "images_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\Animal\\\\0c701217ce0d151a4048f559b3613070.jpg'\n",
      "b'images\\\\Animal\\\\383dd362b1dde98b5f28cb71b54238bd.jpg'\n",
      "b'images\\\\Animal\\\\7f2bcfec799d4bc0e57e5fd42af3518c--white-lions-white-tigers.jpg'\n",
      "b'images\\\\Animal\\\\8c97042a7caf01e2c7609f33b5c17e55.jpg'\n",
      "b'images\\\\Animal\\\\HD-wallpaper-dreamy.jpg'\n",
      "b'images\\\\Animal\\\\cute-baby-chicks-animal-wp1iuazbb451hz2c.jpg'\n"
     ]
    }
   ],
   "source": [
    "for file in images_dataset.take(6): # here it store image path \n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\Gold fish\\\\a-Ryukin-Goldfish-in-aquarium_dien_Shutterstock.jpg'\n",
      "b'images\\\\Gold fish\\\\feeder-goldfish_JuanCarlosPalauDiaz_Shutterstock.png'\n",
      "b'images\\\\Animal\\\\images (15).jpeg'\n",
      "b'images\\\\Gold fish\\\\final_coral_reef_03 (1).webp'\n",
      "b'images\\\\Gold fish\\\\1.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_dataset=images_dataset.shuffle(200) # shuffling\n",
    "for file in images_dataset.take(5):\n",
    "    print(file.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_count=len(images_dataset)\n",
    "images_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=['Animal','Gold fish']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-3: Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Note:\n",
    "    Here x_train is actual image data and ytrain is image label(Animal, gold fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size=int(images_count*0.8)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=images_dataset.take(train_size)\n",
    "train_data\n",
    "\n",
    "test_data=images_dataset.skip(train_size) # oposit of take\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Retrive Label (Fish & Animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'Animal', '0c701217ce0d151a4048f559b3613070.jpg']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='images\\\\Animal\\\\0c701217ce0d151a4048f559b3613070.jpg'\n",
    "s.split('\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Animal'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split('\\\\')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\Gold fish\\\\download (1).jpeg'\n",
      "b'images\\\\Gold fish\\\\7.jpg'\n",
      "b'images\\\\Animal\\\\images (15).jpeg'\n",
      "b'images\\\\Gold fish\\\\98032132f77f209890e1120374e9f281--funny-iphone-wallpaper-desktop-wallpapers.jpg'\n"
     ]
    }
   ],
   "source": [
    "for t in train_data.take(4):\n",
    "    print(t.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Retrive y_train | label (Animal,Fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    path= tf.strings.split(file_path,os.path.sep) # os.path.sep means os seperator which seperator the file path\n",
    "    return path[-2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Animal'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label('images\\\\Animal\\\\0c701217ce0d151a4048f559b3613070.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Gold fish'\n",
      "b'Animal'\n",
      "b'Animal'\n"
     ]
    }
   ],
   "source": [
    "for label in train_data.map(get_label):\n",
    "    print(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label=get_label(file_path)\n",
    "    img=tf.io.read_file(file_path) # load the raw data from the file as a string\n",
    "    img=tf.image.decode_jpeg(img)\n",
    "    img=tf.image.resize(img,[128,128]) # resize the image\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [253.9388 , 253.9388 , 253.9388 ],\n",
       "        [253.91797, 253.91797, 253.91797]],\n",
       "\n",
       "       [[254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ],\n",
       "        [254.     , 254.     , 254.     ]]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = process_image('images\\\\Animal\\\\0c701217ce0d151a4048f559b3613070.jpg')\n",
    "img.numpy()[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Retrive x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(process_image)\n",
    "test_data = test_data.map(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Image tf.Tensor(\n",
      "[[[154.66016  186.23438  214.23438 ]\n",
      "  [151.02344  185.21484  212.40625 ]\n",
      "  [147.81366  183.2633   211.51953 ]\n",
      "  ...\n",
      "  [212.28516  208.23828  205.20038 ]\n",
      "  [214.7099   210.7757   209.84149 ]\n",
      "  [212.30133  210.30133  211.30133 ]]\n",
      "\n",
      " [[144.98047  180.70312  209.27734 ]\n",
      "  [141.57812  178.875    207.44922 ]\n",
      "  [138.40625  177.68317  207.3711  ]\n",
      "  ...\n",
      "  [214.24219  210.1684   208.34375 ]\n",
      "  [210.33514  207.62994  208.12213 ]\n",
      "  [208.82874  207.27734  209.20148 ]]\n",
      "\n",
      " [[137.0055   179.       210.8711  ]\n",
      "  [134.34375  177.17188  209.04297 ]\n",
      "  [132.08405  176.86731  209.83215 ]\n",
      "  ...\n",
      "  [215.04889  210.13269  213.78528 ]\n",
      "  [204.00739  202.17188  207.01477 ]\n",
      "  [202.80743  201.79803  207.65234 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[196.78046  178.78046   94.78046 ]\n",
      "  [223.81793  205.81793  119.81793 ]\n",
      "  [211.2995   194.2995   104.2995  ]\n",
      "  ...\n",
      "  [129.81201  110.81201   33.807983]\n",
      "  [203.74841  184.74841  107.74841 ]\n",
      "  [141.12976  122.12976   45.17273 ]]\n",
      "\n",
      " [[165.32776  147.32776   63.6604  ]\n",
      "  [156.62543  138.62543   52.77179 ]\n",
      "  [208.07623  191.07623  101.88788 ]\n",
      "  ...\n",
      "  [131.72565  111.914     34.008606]\n",
      "  [176.34772  156.28992   79.64252 ]\n",
      "  [148.61884  128.84045   52.674133]]\n",
      "\n",
      " [[168.75458  150.43872   69.153015]\n",
      "  [165.90027  147.90027   65.20044 ]\n",
      "  [157.10132  139.29272   52.891968]\n",
      "  ...\n",
      "  [148.73395  126.21051   46.364014]\n",
      "  [158.28802  135.85608   58.067017]\n",
      "  [160.20044  138.24786   60.24005 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "**** Label tf.Tensor(b'Animal', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_data.take(1):\n",
    "    print(\"**** Image\",image)\n",
    "    print(\"**** Label\",label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    | Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Image:  [0.98039216 0.98039216 0.98039216]\n",
      "****Label:  b'Gold fish'\n",
      "****Image:  [0.14901961 0.13725491 0.11764706]\n",
      "****Label:  b'Gold fish'\n",
      "****Image:  [0.02184436 0.06106005 0.01792279]\n",
      "****Label:  b'Gold fish'\n",
      "****Image:  [0.13498774 0.14283088 0.09185049]\n",
      "****Label:  b'Animal'\n",
      "****Image:  [0.37573528 0.43063724 0.29338235]\n",
      "****Label:  b'Gold fish'\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_data.take(5):\n",
    "    print(\"****Image: \",image.numpy()[0][0])\n",
    "    print(\"****Label: \",label.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
